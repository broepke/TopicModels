{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianroepke/miniforge3/envs/NLP/lib/python3.9/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/Users/brianroepke/miniforge3/envs/NLP/lib/python3.9/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('tesla_clean.pkl')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['Discussion_Clean'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hear incentive tax credit long offer first car order true'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Discussion_Clean'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = ['the', 'a', 'an', 'of', 'and', 'or', 'in', 'for', 'to', 'at', 'by', 'from', 'with', 'on', 'as', 'but', 'is', 'are', 'was', 'were', 'be', 'been', 'am', 'i', 'me', 'my', 'we', 'our', 'you', 'your', 'yours', 'he', 'she', 'it', 'they', 'them', 'their', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'can', 'will', 'would', 'should', 'could', 'may', 'might', 'must', 'ought', 'i', 'you', 'he', 'she', 'it', 'thank', 'lol', 'yes', 'nope', 'get', 'go', 'one', 'see', 'haha', 'nice', 'flag', 'spam', 'shit', 'here', 'look', 'use', 'good', 'say', 'think', 'know', 'nah', 'ah', 'time', 'fish', 'troll', 'nazi', 'ha', 'bye', 'ok', 'okay', 'fucking', 'andy', 'idiot', 'httpsteslatapcomarticlesownersmanualcompanionsearch', 'fishy', 'fishev', 'evil', 'tanya', 'lilbean', 'eaglespdx', 'lie', 'maxxer', 's', 'nt', 'not', 'do', 'like', 'well', 've', 'try']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "texts = [\n",
    "    [word for word in document.split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(texts, min_count=20)\n",
    "for idx in range(len(texts)):\n",
    "    for token in bigram[texts[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            texts[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# Filter out words that occur less than X documents, or more than X% of the documents.\n",
    "dictionary.filter_extremes(no_below=50, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corpus.  This is a Term Frequency or Bag of Words representation.\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 2755\n",
      "Number of documents: 54335\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique tokens: {len(dictionary)}')\n",
    "print(f'Number of documents: {len(corpus)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use TF-IDF instead of BOW\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Word2Vec(sentences=documents, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Topic Modeling Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an arbitrary number of topics to start\n",
    "NUM_TOPICS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scoring (model, corpus, text, dictionary, perplex=False):\n",
    "\n",
    "    # Compute Perplexity\n",
    "    # a measure of how good the model is. lower the better.\n",
    "    if perplex:\n",
    "        print('Perplexity: ', model.log_perplexity(corpus))  \n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model = CoherenceModel(model=model, \n",
    "                                         texts=text, \n",
    "                                         dictionary=dictionary, \n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=NUM_TOPICS, random_state=42)\n",
    "\n",
    "model_scoring(lda_model, corpus, texts, dictionary, perplex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LsiModel(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary)\n",
    "\n",
    "model_scoring(lsi_model, corpus, texts, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = Nmf(corpus=corpus, num_topics=NUM_TOPICS, id2word=dictionary, random_state=42)\n",
    "\n",
    "model_scoring(nmf_model, corpus, texts, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (Tuning) the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 8\n",
    "# Set training parameters.\n",
    "chunksize = 2000\n",
    "passes = 6\n",
    "iterations = 100\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Best Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, cohere, limit, start=2, step=2):\n",
    "\n",
    "    coherence_values = []\n",
    "    # model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, \n",
    "                         id2word=dictionary, \n",
    "                         num_topics=num_topics,\n",
    "                         chunksize=chunksize,\n",
    "                         alpha='auto',\n",
    "                         eta='auto',\n",
    "                         iterations=iterations,\n",
    "                         passes=passes,\n",
    "                         eval_every=eval_every,\n",
    "                         random_state=42,)\n",
    "        # model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, \n",
    "                                        texts=texts, \n",
    "                                        dictionary=dictionary, \n",
    "                                        coherence=cohere)\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=30\n",
    "start=2\n",
    "step=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values = compute_coherence_values(dictionary=dictionary, \n",
    "                                            corpus=corpus, \n",
    "                                            texts=texts, \n",
    "                                            cohere='c_v', # 'u_mass', 'c_v', 'c_uci', 'c_npmi'\n",
    "                                            start=start, \n",
    "                                            limit=limit, \n",
    "                                            step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# Create a custom x-axis\n",
    "x = range(start, limit, step)\n",
    "\n",
    "# Build the line plot\n",
    "ax = sns.lineplot(x=x, y=coherence_values, color='#238C8C')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title(\"Best Number of Topics for LDA Model\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.xlim(start, limit)\n",
    "plt.xticks(range(2, limit, step))\n",
    "\n",
    "# Add a vertical line to show the optimum number of topics\n",
    "plt.axvline(x[np.argmax(coherence_values)], \n",
    "            color='#F26457', linestyle='--')\n",
    "\n",
    "# Draw a custom legend\n",
    "legend_elements = [Line2D([0], [0], color='#238C8C', \n",
    "                          ls='-', label='Coherence Value (c_v)'),\n",
    "                   Line2D([0], [1], color='#F26457', \n",
    "                          ls='--', label='Optimal Number of Topics')]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('topic_coherence.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Final Model and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 8\n",
    "# Set training parameters.\n",
    "chunksize = 2000\n",
    "passes = 6\n",
    "iterations = 100\n",
    "eval_every = None\n",
    "temp = dictionary[0]\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus=corpus, texts=texts, dictionary=dictionary, topn=10, coherence='c_v')\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / NUM_TOPICS\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# feed the LDA model into the pyLDAvis instance\n",
    "lda_viz = gensimvis.prepare(model, corpus, dictionary, sort_topics=True)\n",
    "\n",
    "pyLDAvis.display(lda_viz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(lda_viz, 'lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.disable_notebook()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5629da87f0f0738fb6d7f5b56890b7158ed7c3cd6e2056d12c1193abac81cb87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
